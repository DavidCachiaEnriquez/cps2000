{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Table Driven Lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: let x:int = __randi 1000;\n",
      "\n",
      "Value: let\t\tType: <Identifier>\n",
      "Value: x\t\tType: <Identifier>\n",
      "Value: :\t\tType: <Other>\n",
      "Value: int\t\tType: <Type>\n",
      "Value: =\t\tType: <Other>\n",
      "Value: __randi\t\tType: <__randi>\n",
      "Value: 1000\t\tType: <IntegerLiteral>\n",
      "Value: ;\t\tType: <Other>\n"
     ]
    }
   ],
   "source": [
    "class Token():\n",
    "    def __init__(self, inputValue, inputType):\n",
    "        self.value = inputValue\n",
    "        self.type = inputType\n",
    "\n",
    "class Lexer:\n",
    "    def __init__(self, input):\n",
    "        self.code = input\n",
    "        self.tokenlist = []\n",
    "        self.pos = 0\n",
    "        \n",
    "        self.tokenTable = [\n",
    "            (r\"\\b(float|int|bool|colour)\\b\", \"<Type>\"),\n",
    "            \n",
    "            (r\"\\b(true|false)\\b\", \"<BooleanLiteral>\"),\n",
    "            (r\"\\d+\\.\\d+\", \"<FloatLiteral>\"),\n",
    "            (r\"\\d+\", \"<IntegerLiteral>\"),\n",
    "            (r\"\\#[0-9a-fA-F]{6}\", \"<ColourLiteral>\"),\n",
    "\n",
    "            (r\"\\b(__width)\\b\", \"<PadWidth>\"),\n",
    "            (r\"\\b(__height)\\b\", \"<PadHeight>\"),\n",
    "\n",
    "            (r\"\\b(__read)\\b\", \"<__read>\"),\n",
    "            (r\"\\b(__randi)\\b\", \"<__randi>\"),\n",
    "\n",
    "            (r\"[a-zA-Z]([a-zA-Z0-9]|_)*\", \"<Identifier>\"),\n",
    "\n",
    "            (r\"[\\*/]|and\", \"<MultiplicativeOp>\"),\n",
    "            (r\"[\\+\\-]|or\", \"<AdditiveOp>\"),\n",
    "            (r\"[\\<\\>]|==|!=|<=|>=\", \"<RelationalOp>\"),\n",
    "\n",
    "            (r\"\\b(__print)\\b\", \"<__print>\"),\n",
    "            (r\"\\b(__delay)\\b\", \"<__delay>\"),\n",
    "            (r\"\\b(__pixelr)\\b\", \"<__pixelr>\"),\n",
    "            (r\"\\b(__pixel)\\b\", \"<__pixel>\"),\n",
    "            \n",
    "            (r\"not|let|return|if|else|while|fun\", \"<Keywords>\"),\n",
    "            (r\"[\\,\\(\\)\\-\\=\\:\\;\\{\\}]|->\", \"<Other>\")\n",
    "        ]\n",
    "    \n",
    "    def scanText(self):\n",
    "        # loops while less than size of string\n",
    "        while self.pos < len(self.code):\n",
    "            # ignores whitespace\n",
    "            if self.code[self.pos] == \" \":\n",
    "                self.pos += 1\n",
    "            # if not whitespace\n",
    "            else:\n",
    "                value, type = None, None\n",
    "\n",
    "                # goes through table of patterns\n",
    "                for pattern, tokenType in self.tokenTable:\n",
    "                    match = re.match(pattern, self.code[self.pos:])\n",
    "\n",
    "                    # if they match\n",
    "                    if match is not None:\n",
    "                        type = tokenType\n",
    "                        value = match.group()\n",
    "                        break\n",
    "                \n",
    "                # if value and type remained empyty\n",
    "                if value == None or type == None:\n",
    "                    raise Exception(\"Error in Syntax\")\n",
    "                # if both value and type have been assigned\n",
    "                else:\n",
    "                    self.tokenlist.append(Token(value, type))\n",
    "                    self.pos += len(value)\n",
    "\n",
    "text = 'let x:int = __randi 1000;'\n",
    "lexer = Lexer(text)\n",
    "lexer.scanText()\n",
    "\n",
    "print(\"Text: \" + text + \"\\n\")\n",
    "for token in lexer.tokenlist:\n",
    "    print(\"Value: \" + token.value + \"\\t\\tType: \" + token.type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stringToTest = \"let x true\"\n",
    "# lexer = LexerV2()\n",
    "\n",
    "# lexer.scanCode(stringToTest)\n",
    "# counter = 1\n",
    "# print(\"Code: \" + stringToTest)\n",
    "# for i in lexer.tokens:\n",
    "#     print(\"\\nToken \" + str(counter))\n",
    "#     print(\"Value: \" + i.value + \"\\nType: \" + i.type)\n",
    "#     counter +=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Hand-crafted LL(k) parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - AST XML Generation Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 - Semantic Analysis Pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5 - PixIR Code Generation Pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
